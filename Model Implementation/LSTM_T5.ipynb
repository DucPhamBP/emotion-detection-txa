{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras-tuner) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras-tuner) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from optree->keras->keras-tuner) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_t5 = pd.read_csv('C:/Users/Usuario/emotion-detection-txa/Pretrained_Model Implementation/t5_model_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "# Remove stopwords from the text data\n",
    "data_t5['text'] = data_t5['text'].apply(remove_stopwords)\n",
    "\n",
    "# Prepare data\n",
    "X = data_t5['text']\n",
    "y = data_t5['predicted_label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(set(y_encoded))\n",
    "y_encoded_cat = to_categorical(y_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "data_t5_aux = data_t5\n",
    "data_t5_aux['token_count'] = data_t5_aux['text'].apply(lambda x: len(x.split()))\n",
    "max_length = data_t5_aux['token_count'].max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_features = 100 #parameter to optimize\n",
    "tokenizer = Tokenizer(num_words = max_features, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_length = max_length  # Maximum length of input sequences\n",
    "X_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "vocab_size = max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2521s\u001b[0m 57ms/step - accuracy: 0.4695 - loss: 1.2725 - val_accuracy: 0.5188 - val_loss: 1.1768\n",
      "Epoch 2/6\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2125s\u001b[0m 48ms/step - accuracy: 0.5299 - loss: 1.1549 - val_accuracy: 0.5453 - val_loss: 1.1123\n",
      "Epoch 3/6\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2141s\u001b[0m 49ms/step - accuracy: 0.5624 - loss: 1.0887 - val_accuracy: 0.5863 - val_loss: 1.0641\n",
      "Epoch 4/6\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2178s\u001b[0m 49ms/step - accuracy: 0.5788 - loss: 1.0598 - val_accuracy: 0.5816 - val_loss: 1.0638\n",
      "Epoch 5/6\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2232s\u001b[0m 51ms/step - accuracy: 0.5878 - loss: 1.0438 - val_accuracy: 0.5981 - val_loss: 1.0353\n",
      "Epoch 6/6\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2212s\u001b[0m 50ms/step - accuracy: 0.5953 - loss: 1.0290 - val_accuracy: 0.5948 - val_loss: 1.0315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26c9fb05280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))     \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Use 'softmax' for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=6, batch_size=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - accuracy: 0.5953 - loss: 1.0375\n",
      "Test Accuracy: 0.5991\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_1d = np.argmax(y_test, axis=1)\n",
    "y_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.59      0.57      7338\n",
      "           1       0.48      0.27      0.35      2970\n",
      "           2       0.63      0.77      0.69     11001\n",
      "           3       0.28      0.04      0.08       112\n",
      "           4       0.72      0.37      0.49      2809\n",
      "           5       0.95      0.07      0.14       244\n",
      "\n",
      "    accuracy                           0.60     24474\n",
      "   macro avg       0.60      0.35      0.38     24474\n",
      "weighted avg       0.60      0.60      0.58     24474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test_1d, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [02h 22m 39s]\n",
      "val_accuracy: 0.5897344052791595\n",
      "\n",
      "Best val_accuracy So Far: 0.5988508760929108\n",
      "Total elapsed time: 1d 12h 52m 29s\n"
     ]
    }
   ],
   "source": [
    "# Función para construir el modelo\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_features, output_dim=hp.Choice('output_dim', [64, 128, 256]), input_length=max_sequence_length))\n",
    "    model.add(LSTM(hp.Int('lstm_units1', min_value=64, max_value=256, step=64), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(hp.Int('lstm_units2', min_value=32, max_value=128, step=32)))\n",
    "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Configurar la búsqueda\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=25,  # Número de configuraciones a probar\n",
    "    executions_per_trial=2,  # Número de ejecuciones por configuración\n",
    "    directory='tuner_results',\n",
    "    project_name='emotion_classification'\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda\n",
    "tuner.search(X_train, y_train, epochs=5, validation_split=0.2, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'output_dim': 256, 'lstm_units1': 256, 'dropout_rate': 0.30000000000000004, 'lstm_units2': 64}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los mejores hiperparámetros\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\", best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7154s\u001b[0m 162ms/step - accuracy: 0.4583 - loss: 1.2869 - val_accuracy: 0.5190 - val_loss: 1.1790\n",
      "Epoch 2/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6512s\u001b[0m 148ms/step - accuracy: 0.5286 - loss: 1.1673 - val_accuracy: 0.5495 - val_loss: 1.1233\n",
      "Epoch 3/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6237s\u001b[0m 142ms/step - accuracy: 0.5528 - loss: 1.1212 - val_accuracy: 0.5617 - val_loss: 1.1022\n",
      "Epoch 4/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6308s\u001b[0m 143ms/step - accuracy: 0.5571 - loss: 1.1073 - val_accuracy: 0.5659 - val_loss: 1.0834\n",
      "Epoch 5/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6381s\u001b[0m 145ms/step - accuracy: 0.5644 - loss: 1.0911 - val_accuracy: 0.5731 - val_loss: 1.0724\n",
      "Epoch 6/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6511s\u001b[0m 148ms/step - accuracy: 0.5660 - loss: 1.0889 - val_accuracy: 0.5756 - val_loss: 1.0727\n",
      "Epoch 7/7\n",
      "\u001b[1m44053/44053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6954s\u001b[0m 158ms/step - accuracy: 0.5704 - loss: 1.0835 - val_accuracy: 0.5762 - val_loss: 1.0772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26cd19aa180>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=256, input_length=max_sequence_length))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64))     \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Use 'softmax' for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=7, batch_size=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 265ms/step - accuracy: 0.5740 - loss: 1.0753\n",
      "Test Accuracy: 0.5785\n",
      "\u001b[1m765/765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 265ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_1d = np.argmax(y_test, axis=1)\n",
    "y_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.57      0.54      7338\n",
      "           1       0.53      0.16      0.24      2970\n",
      "           2       0.61      0.78      0.68     11001\n",
      "           3       0.41      0.06      0.11       112\n",
      "           4       0.74      0.31      0.44      2809\n",
      "           5       0.91      0.04      0.08       244\n",
      "\n",
      "    accuracy                           0.58     24474\n",
      "   macro avg       0.62      0.32      0.35     24474\n",
      "weighted avg       0.59      0.58      0.55     24474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test_1d, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
