{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\naomi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\naomi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\naomi\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 6.3/390.3 MB 35.1 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 14.7/390.3 MB 38.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 21.0/390.3 MB 36.8 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 26.5/390.3 MB 32.9 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 34.6/390.3 MB 34.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 43.0/390.3 MB 35.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 51.6/390.3 MB 35.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 59.5/390.3 MB 36.1 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 67.6/390.3 MB 36.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 76.0/390.3 MB 36.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 84.1/390.3 MB 37.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 92.0/390.3 MB 37.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 99.6/390.3 MB 37.0 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 108.3/390.3 MB 37.4 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 115.9/390.3 MB 37.4 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 124.0/390.3 MB 37.5 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 132.1/390.3 MB 37.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 140.5/390.3 MB 37.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 148.1/390.3 MB 37.5 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 153.6/390.3 MB 37.0 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 161.5/390.3 MB 37.1 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 169.6/390.3 MB 37.1 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 178.0/390.3 MB 37.3 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 186.6/390.3 MB 37.5 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 195.3/390.3 MB 37.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 204.2/390.3 MB 37.8 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 212.9/390.3 MB 37.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 219.4/390.3 MB 37.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 227.5/390.3 MB 37.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 235.9/390.3 MB 37.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 244.3/390.3 MB 37.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 252.4/390.3 MB 37.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 260.0/390.3 MB 37.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 268.2/390.3 MB 37.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 276.6/390.3 MB 37.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 284.2/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 292.3/390.3 MB 38.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 300.7/390.3 MB 38.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 309.3/390.3 MB 38.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 317.2/390.3 MB 38.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 324.0/390.3 MB 38.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 332.4/390.3 MB 38.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 340.8/390.3 MB 38.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 349.2/390.3 MB 38.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 357.6/390.3 MB 38.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 365.4/390.3 MB 38.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.6/390.3 MB 38.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.7/390.3 MB 38.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 33.6 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 29.5 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 35.0 MB/s eta 0:00:00\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 8.1/26.4 MB 38.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.8/26.4 MB 38.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 39.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 35.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 37.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\naomi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_t5 = pd.read_csv('C:/Users/naomi/Downloads/labeled_data_reddit_text_yangswei_85.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remotework</td>\n",
       "      <td>1fy22yp</td>\n",
       "      <td>t3_1fy22yp</td>\n",
       "      <td>2024-10-07 13:03:07</td>\n",
       "      <td>17</td>\n",
       "      <td>Oh how offices have changed the movie office s...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>remotework</td>\n",
       "      <td>1fy22yp</td>\n",
       "      <td>t3_1fy22yp</td>\n",
       "      <td>2024-10-07 11:38:45</td>\n",
       "      <td>79</td>\n",
       "      <td>Oh how offices have changed when i was in the ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remotework</td>\n",
       "      <td>1fy22yp</td>\n",
       "      <td>t3_1fy22yp</td>\n",
       "      <td>2024-10-07 11:41:54</td>\n",
       "      <td>66</td>\n",
       "      <td>Oh how offices have changed you were also sexu...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remotework</td>\n",
       "      <td>1fy22yp</td>\n",
       "      <td>t3_1fy22yp</td>\n",
       "      <td>2024-10-07 16:17:46</td>\n",
       "      <td>11</td>\n",
       "      <td>Oh how offices have changed overwhelmingly mos...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remotework</td>\n",
       "      <td>1fy22yp</td>\n",
       "      <td>t3_1fy22yp</td>\n",
       "      <td>2024-10-07 11:43:37</td>\n",
       "      <td>28</td>\n",
       "      <td>Oh how offices have changed this isn't even cl...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  link_id   parent_id          created_utc  upvotes  \\\n",
       "0  remotework  1fy22yp  t3_1fy22yp  2024-10-07 13:03:07       17   \n",
       "1  remotework  1fy22yp  t3_1fy22yp  2024-10-07 11:38:45       79   \n",
       "2  remotework  1fy22yp  t3_1fy22yp  2024-10-07 11:41:54       66   \n",
       "3  remotework  1fy22yp  t3_1fy22yp  2024-10-07 16:17:46       11   \n",
       "4  remotework  1fy22yp  t3_1fy22yp  2024-10-07 11:43:37       28   \n",
       "\n",
       "                                                text predictions  \n",
       "0  Oh how offices have changed the movie office s...         joy  \n",
       "1  Oh how offices have changed when i was in the ...     sadness  \n",
       "2  Oh how offices have changed you were also sexu...       anger  \n",
       "3  Oh how offices have changed overwhelmingly mos...     sadness  \n",
       "4  Oh how offices have changed this isn't even cl...         joy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "# Remove stopwords from the text data\n",
    "data_t5['text'] = data_t5['text'].apply(remove_stopwords)\n",
    "\n",
    "# Prepare data\n",
    "X = data_t5['text']\n",
    "y = data_t5['predictions']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(set(y_encoded))\n",
    "y_encoded_cat = to_categorical(y_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "data_t5_aux = data_t5\n",
    "data_t5_aux['token_count'] = data_t5_aux['text'].apply(lambda x: len(x.split()))\n",
    "max_length = data_t5_aux['token_count'].max()\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_features = 100 #parameter to optimize\n",
    "tokenizer = Tokenizer(num_words = max_features, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_length = max_length  # Maximum length of input sequences\n",
    "X_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "vocab_size = max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "max_features = 5000\n",
    "# TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=max_features)  \n",
    "X_tfidf = tfidf.fit_transform(data_t5['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 29ms/step - accuracy: 0.5958 - loss: 1.1661 - val_accuracy: 0.6039 - val_loss: 1.1067\n",
      "Epoch 2/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m908s\u001b[0m 23ms/step - accuracy: 0.6007 - loss: 1.1154 - val_accuracy: 0.6131 - val_loss: 1.0794\n",
      "Epoch 3/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 21ms/step - accuracy: 0.6144 - loss: 1.0807 - val_accuracy: 0.6203 - val_loss: 1.0548\n",
      "Epoch 4/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 20ms/step - accuracy: 0.6210 - loss: 1.0577 - val_accuracy: 0.6246 - val_loss: 1.0472\n",
      "Epoch 5/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m841s\u001b[0m 21ms/step - accuracy: 0.6256 - loss: 1.0445 - val_accuracy: 0.6249 - val_loss: 1.0364\n",
      "Epoch 6/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m841s\u001b[0m 21ms/step - accuracy: 0.6271 - loss: 1.0422 - val_accuracy: 0.6390 - val_loss: 1.0270\n",
      "Epoch 7/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 20ms/step - accuracy: 0.6299 - loss: 1.0332 - val_accuracy: 0.6339 - val_loss: 1.0271\n",
      "Epoch 8/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 21ms/step - accuracy: 0.6331 - loss: 1.0247 - val_accuracy: 0.6404 - val_loss: 1.0163\n",
      "Epoch 9/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 21ms/step - accuracy: 0.6342 - loss: 1.0216 - val_accuracy: 0.6329 - val_loss: 1.0247\n",
      "Epoch 10/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 21ms/step - accuracy: 0.6328 - loss: 1.0283 - val_accuracy: 0.6395 - val_loss: 1.0231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d050ba7c50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))     \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Use 'softmax' for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.6418 - loss: 1.0093\n",
      "Test Accuracy: 0.6411\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.55      0.21      0.31      3332\\n           1       0.68      0.11      0.20      1097\\n           2       0.65      0.95      0.77     13447\\n           3       0.00      0.00      0.00       164\\n           4       0.62      0.16      0.26      3955\\n           5       0.88      0.05      0.10       294\\n\\n    accuracy                           0.64     22289\\n   macro avg       0.56      0.25      0.27     22289\\nweighted avg       0.63      0.64      0.57     22289\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "y_test_1d = np.argmax(y_test, axis=1)\n",
    "y_test_1d\n",
    "\n",
    "print(classification_report(y_test_1d, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.21      0.31      3332\n",
      "           1       0.68      0.11      0.20      1097\n",
      "           2       0.65      0.95      0.77     13447\n",
      "           3       0.00      0.00      0.00       164\n",
      "           4       0.62      0.16      0.26      3955\n",
      "           5       0.88      0.05      0.10       294\n",
      "\n",
      "    accuracy                           0.64     22289\n",
      "   macro avg       0.56      0.25      0.27     22289\n",
      "weighted avg       0.63      0.64      0.57     22289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_1d, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tunerNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras-tuner) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\naomi\\appdata\\roaming\\python\\python312\\site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (2.0.2)\n",
      "Requirement already satisfied: rich in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->keras-tuner) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->keras-tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\naomi\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\naomi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_features, output_dim=hp.Choice('output_dim', [64, 128, 256]), input_length=max_sequence_length))\n",
    "    model.add(LSTM(hp.Int('lstm_units1', min_value=64, max_value=256, step=64), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(hp.Int('lstm_units2', min_value=32, max_value=128, step=32)))\n",
    "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=25,  \n",
    "    executions_per_trial=2,  \n",
    "    directory='tuner_results',\n",
    "    project_name='emotion_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [02h 24m 13s]\n",
      "val_accuracy: 0.6335034370422363\n",
      "\n",
      "Best val_accuracy So Far: 0.6374291777610779\n",
      "Total elapsed time: 1d 11h 14m 21s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=7, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\", best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3737s\u001b[0m 93ms/step - accuracy: 0.5987 - loss: 1.1699 - val_accuracy: 0.6026 - val_loss: 1.1260\n",
      "Epoch 2/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2711s\u001b[0m 68ms/step - accuracy: 0.6005 - loss: 1.1319 - val_accuracy: 0.6094 - val_loss: 1.1041\n",
      "Epoch 3/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2757s\u001b[0m 69ms/step - accuracy: 0.6020 - loss: 1.1167 - val_accuracy: 0.6123 - val_loss: 1.0854\n",
      "Epoch 4/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2855s\u001b[0m 71ms/step - accuracy: 0.6064 - loss: 1.0997 - val_accuracy: 0.6169 - val_loss: 1.0780\n",
      "Epoch 5/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2761s\u001b[0m 69ms/step - accuracy: 0.6106 - loss: 1.0987 - val_accuracy: 0.6165 - val_loss: 1.0772\n",
      "Epoch 6/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2822s\u001b[0m 70ms/step - accuracy: 0.6130 - loss: 1.0885 - val_accuracy: 0.6184 - val_loss: 1.0755\n",
      "Epoch 7/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3663s\u001b[0m 91ms/step - accuracy: 0.6116 - loss: 1.0892 - val_accuracy: 0.6231 - val_loss: 1.0586\n",
      "Epoch 8/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6307s\u001b[0m 157ms/step - accuracy: 0.6125 - loss: 1.0926 - val_accuracy: 0.6207 - val_loss: 1.0662\n",
      "Epoch 9/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2924s\u001b[0m 73ms/step - accuracy: 0.6145 - loss: 1.0859 - val_accuracy: 0.6183 - val_loss: 1.0759\n",
      "Epoch 10/10\n",
      "\u001b[1m40118/40118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2849s\u001b[0m 71ms/step - accuracy: 0.6146 - loss: 1.0834 - val_accuracy: 0.6173 - val_loss: 1.0790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x239104a52e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=256, input_length=max_sequence_length))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(96))     \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 41ms/step - accuracy: 0.6206 - loss: 1.0654\n",
      "Test Accuracy: 0.6191\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 0, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "y_test_1d = np.argmax(y_test, axis=1)\n",
    "y_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.08      0.15      3332\n",
      "           1       0.74      0.02      0.04      1097\n",
      "           2       0.62      1.00      0.76     13447\n",
      "           3       0.00      0.00      0.00       164\n",
      "           4       0.77      0.03      0.06      3955\n",
      "           5       0.00      0.00      0.00       294\n",
      "\n",
      "    accuracy                           0.62     22289\n",
      "   macro avg       0.48      0.19      0.17     22289\n",
      "weighted avg       0.66      0.62      0.49     22289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naomi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test_1d, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
