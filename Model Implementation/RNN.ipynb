{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocabulary_size, num_labels, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        vocabulary_size (int): The size of the vocabulary (number of unique tokens in the input text).\n",
    "        num_labels (int): The number of output classes (labels).\n",
    "        embedding_dim (int): The dimension of the word embeddings (the vector size representing each word).\n",
    "        hidden_dim (int): The number of units in the hidden state of the RNN.\n",
    "        n_layers (int): The number of RNN layers to stack.\n",
    "        dropout (float, optional): The probability for dropout regularization (default is 0.5).\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out, hidden = self.rnn(embedded)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out[:, -1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure GPU or CPU compatibility\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data = ...  \n",
    "train_labels = ... \n",
    "val_data = ...\n",
    "val_loader = ...\n",
    "\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.long)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "val_data = torch.tensor(val_data, dtype=torch.long)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "val_dataset = TensorDataset(val_data, val_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "param_grid = {\n",
    "    'embedding_dim': [100, 200, 400],\n",
    "    'hidden_dim': [128, 256, 512],\n",
    "    'n_layers': [1, 2],\n",
    "    'learning_rate': [0.001, 0.0001]\n",
    "}\n",
    "\n",
    "best_params, best_accuracy = tune_model_hyperparameters(train_data, train_labels, param_grid, epochs)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "embedding_dim, hidden_dim, n_layers, learning_rate = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 6  # Ekman's six emotions\n",
    "\n",
    "vocabulary_size = len(train_data[0]) + 1 \n",
    "\n",
    "rnn_model = RNN(vocabulary_size, num_labels, embedding_dim, hidden_dim, n_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RNN Start Training:\\n\")\n",
    "train_losses, val_losses, val_accs = train_and_validate(\n",
    "    rnn_model, optimizer, criterion, train_loader, val_loader, epochs, device\n",
    ")\n",
    "plot_losses(\"RNN\", train_losses, val_losses, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
